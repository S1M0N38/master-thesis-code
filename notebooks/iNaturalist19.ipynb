{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf3eb0-0a72-48af-b214-695f7df2b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import utils\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from collections.abc import Callable\n",
    "from functools import partial\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0756f-d8ea-4b6d-9e96-636ed6a0033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"iNaturalist19\"\n",
    "PATH_EXPERIMENTS = pathlib.Path(\"..\") / \"experiments\" / DATASET\n",
    "PATH_RESULTS = pathlib.Path(\".\") / \"results\"\n",
    "\n",
    "# TODO ln datasets2 at \"..\"\n",
    "PATH_DATASET = pathlib.Path(\"/Users/simo\") / \"Developer\" / \"datasets2\" / \"datasets\" / DATASET\n",
    "PATH_ENCODINGS = PATH_DATASET / \"encodings\"\n",
    "HIERARCHY = np.load(PATH_DATASET / \"hierarchy\" / \"hierarchy.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca07c9-4161-4bed-b90c-60ce68c9b590",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "- **xe-onehot**: the baseline, i.e. one-hot encoding + cross entropy loss\n",
    "- **xe-b3p-beta\\***: a type of hierarchical encoding propose in \"Beyond One-Hot Encoding: Injecting Semantics to Drive Image Classifiers\" by Perotti, Bertolotto, Pastor and Panisson hence \"b3p\". This approch required to choose $\\beta \\in [0, 1]$, an hyperparameter the rappresent the \"amount of one hot encoding\".\n",
    "- **xe-mbm-beta\\***: a type of hierarchical encoding proposed in \"Making Better Mistakes: Leveraging Class Hierarchies with Deep Networks\" by Bertinetto et al. $\\beta \\rightarrow +\\infty \\Rightarrow \\textrm{mbm} \\rightarrow \\textrm{onehot}$\n",
    "- **cd-barz-denzler**: a type of hierarchical encoding proposed in \"Hierarchy-based Image Embeddings for Semantic Image Retrieval\" by Barz and Denzler\n",
    "- **cd-desc-pca-n_components\\***: descriptions encodings, gpt + ada + pca to n_components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58273c69-8de0-4dbe-a310-1c701cf5c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    #xe-onehot\n",
    "    \"xe-onehot\":[\n",
    "        \"0810_1157_d654214a_xe-onehot\",\n",
    "    ],\n",
    "\n",
    "    # cd-barz-denzler\n",
    "    \"cd-barz-denzler\":[\n",
    "        \"0810_2203_538b8970_cd-barz-denzler\",\n",
    "    ],\n",
    "    \n",
    "    #xe-b3p\n",
    "     \"xe-b3p-beta0.1\" : [\n",
    "         \"0814_1130_4c1708e6_xe-b3p-beta0.1\",\n",
    "     ],\n",
    "     \"xe-b3p-beta0.2\" : [\n",
    "         \"0816_0709_636ef7c0_xe-b3p-beta0.2\",\n",
    "     ],\n",
    "    \"xe-b3p-beta0.3\" : [\n",
    "        \"0817_1729_6c02220c_xe-b3p-beta0.3\",\n",
    "    ],\n",
    "    \"xe-b3p-beta0.4\" : [\n",
    "        \"0818_1843_cff54970_xe-b3p-beta0.4\",\n",
    "    ],\n",
    "    \"xe-b3p-beta0.5\" : [\n",
    "        \"0819_1329_2432f7ac_xe-b3p-beta0.5\",\n",
    "    ],\n",
    "    \"xe-b3p-beta0.6\" : [\n",
    "        \"0820_1117_6e2b0835_xe-b3p-beta0.6\",\n",
    "    ],\n",
    "    \"xe-b3p-beta0.7\" : [\n",
    "        \"0821_0908_6f9d1756_xe-b3p-beta0.7\",\n",
    "    ],\n",
    "    \"xe-b3p-beta0.8\" : [\n",
    "        \"0822_1913_b681b04f_xe-b3p-beta0.8\",\n",
    "    ],\n",
    "    \"xe-b3p-beta0.9\" : [\n",
    "        \"0824_0253_79cffac7_xe-b3p-beta0.9\",\n",
    "    ],\n",
    "\n",
    "    # xe-mbm\n",
    "    \"xe-mbm-beta1.0\" : [\n",
    "        \"0825_0507_68906d90_xe-mbm-beta1.0\",\n",
    "    ],\n",
    "    \"xe-mbm-beta2.0\" : [\n",
    "        \"0825_1813_619ded60_xe-mbm-beta2.0\",\n",
    "    ],\n",
    "    \"xe-mbm-beta3.0\" : [\n",
    "        \"0826_0104_70d32692_xe-mbm-beta3.0\",\n",
    "    ],\n",
    "    \"xe-mbm-beta4.0\" : [\n",
    "        \"0826_1131_7c443b7d_xe-mbm-beta4.0\",\n",
    "    ],\n",
    "    \"xe-mbm-beta5.0\" : [\n",
    "        \"0826_2321_e40a7d5c_xe-mbm-beta5.0\",\n",
    "    ],\n",
    "    \"xe-mbm-beta10.0\" : [\n",
    "        \"0827_2105_696c59cb_xe-mbm-beta10.0\",\n",
    "    ],\n",
    "    \"xe-mbm-beta15.0\" : [\n",
    "        \"0829_1305_3cea2b42_xe-mbm-beta15.0\",\n",
    "    ],\n",
    "    \"xe-mbm-beta20.0\" : [\n",
    "        \"0831_0606_329b467a_xe-mbm-beta20.0\",\n",
    "    ],\n",
    "    \"xe-mbm-beta30.0\" : [\n",
    "        \"0901_2319_b85f5f2a_xe-mbm-beta30.0\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "experiments_ = {\n",
    "    value: key\n",
    "    for key, values in experiments.items()\n",
    "    for value in values\n",
    "}\n",
    "\n",
    "encodings = {\n",
    "    # xe-onehot\n",
    "    \"xe-onehot\": np.eye(HIERARCHY.shape[-1]),\n",
    "\n",
    "    # xe-b3p\n",
    "    \"xe-b3p-beta0.1\": np.load(PATH_ENCODINGS / \"b3p\" / \"beta0.1.npy\"),\n",
    "    \"xe-b3p-beta0.2\": np.load(PATH_ENCODINGS / \"b3p\" / \"beta0.2.npy\"),\n",
    "    \"xe-b3p-beta0.3\": np.load(PATH_ENCODINGS / \"b3p\" / \"beta0.3.npy\"),\n",
    "    \"xe-b3p-beta0.4\": np.load(PATH_ENCODINGS / \"b3p\" / \"beta0.4.npy\"),\n",
    "    \"xe-b3p-beta0.5\": np.load(PATH_ENCODINGS / \"b3p\" / \"beta0.5.npy\"),\n",
    "    \"xe-b3p-beta0.6\": np.load(PATH_ENCODINGS / \"b3p\" / \"beta0.6.npy\"),\n",
    "    \"xe-b3p-beta0.7\": np.load(PATH_ENCODINGS / \"b3p\" / \"beta0.7.npy\"),\n",
    "    \"xe-b3p-beta0.8\": np.load(PATH_ENCODINGS / \"b3p\" / \"beta0.8.npy\"),\n",
    "    \"xe-b3p-beta0.9\": np.load(PATH_ENCODINGS / \"b3p\" / \"beta0.9.npy\"),\n",
    "    \n",
    "    # xe-mbm\n",
    "    \"xe-mbm-beta1.0\": np.load(PATH_ENCODINGS / \"mbm\" / \"beta1.0.npy\"),\n",
    "    \"xe-mbm-beta2.0\": np.load(PATH_ENCODINGS / \"mbm\" / \"beta2.0.npy\"),\n",
    "    \"xe-mbm-beta3.0\": np.load(PATH_ENCODINGS / \"mbm\" / \"beta3.0.npy\"),\n",
    "    \"xe-mbm-beta4.0\": np.load(PATH_ENCODINGS / \"mbm\" / \"beta4.0.npy\"),\n",
    "    \"xe-mbm-beta5.0\": np.load(PATH_ENCODINGS / \"mbm\" / \"beta5.0.npy\"),\n",
    "    \"xe-mbm-beta10.0\": np.load(PATH_ENCODINGS / \"mbm\" / \"beta10.0.npy\"),\n",
    "    \"xe-mbm-beta15.0\": np.load(PATH_ENCODINGS / \"mbm\" / \"beta15.0.npy\"),\n",
    "    \"xe-mbm-beta20.0\": np.load(PATH_ENCODINGS / \"mbm\" / \"beta20.0.npy\"),\n",
    "    \"xe-mbm-beta30.0\": np.load(PATH_ENCODINGS / \"mbm\" / \"beta30.0.npy\"),\n",
    "\n",
    "    # cd-barz-denzler\n",
    "    \"cd-barz-denzler\": np.load(PATH_ENCODINGS / \"barz-denzler.npy\"),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc6ff2-406c-4929-b809-912a038498e0",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "Metrics are a scalar values that capture one aspect of model performance.\n",
    "They are computed on test split of the dataset (or on validation split if test does not exists).\n",
    "\n",
    "They can be compute by considering top k (k) predictions of the models at different hierarchy level (l).\n",
    "\n",
    "- **error_rate*** number of misclassified samples over total samples. It account for the number of error (quantity)\n",
    "- **hier_dist*** hierarchical distance are the predictions weighted by lca matrix over the number of total samples (quantity and quality of error).\n",
    "- **hier_dist_mistake** hierarchical distance mistake are are the predictions weighted by lca matrix over the number of misclassified samples. It represent the severity of errors (quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac2a6a-40ed-4697-bf62-fd076c5f66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_labels(exp):\n",
    "    # Load test results\n",
    "    data = np.load(PATH_EXPERIMENTS / exp / \"outputs_targets.npz\")\n",
    "    outputs, targets = data[\"outputs\"], data[\"targets\"]\n",
    "\n",
    "    # For one-hot encoding targets are already class index (aka labels)\n",
    "    # Convert back to one hot encoding to be consistent with others encondings\n",
    "    if targets.shape[-1] == 1:\n",
    "        labels = targets.squeeze().astype(int)\n",
    "        targets = np.eye(HIERARCHY.shape[-1])[labels]\n",
    "\n",
    "    # Select the encoder matrix\n",
    "    encs = encodings[experiments_[exp]]\n",
    "\n",
    "    # Normalize quantites\n",
    "    outputs /= np.linalg.norm(outputs, axis=1, keepdims=True)\n",
    "    targets /= np.linalg.norm(targets, axis=1, keepdims=True)\n",
    "    encs /= np.linalg.norm(encs, axis=1, keepdims=True)\n",
    "\n",
    "    # Calculate predictions and labels from outputs and targets\n",
    "    preds = outputs @ encs.T\n",
    "    labels = (targets @ encs.T).argmax(axis=-1)\n",
    "    \n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4659d4-be84-4717-bda2-03f59fc78f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(exp: str, level: int = 0, k: int = 1):\n",
    "    return utils.error_rate(*preds_labels(exp), HIERARCHY, level, k)\n",
    "\n",
    "def hier_dist_mistake(exp: str, level: int = 0, k: int = 1):\n",
    "    return utils.hier_dist_mistake(*preds_labels(exp), HIERARCHY, level, k)\n",
    "\n",
    "def hier_dist(exp: str, level: int = 0, k: int = 1):\n",
    "    return utils.hier_dist(*preds_labels(exp), HIERARCHY, level, k)\n",
    "\n",
    "index =  pd.Index(\n",
    "    data=[exp for exps in experiments.values() for exp in exps], \n",
    "    dtype=str, \n",
    "    name=\"experiments\",\n",
    ")\n",
    "\n",
    "columns = pd.MultiIndex.from_product(\n",
    "    iterables=[\n",
    "        range(len(HIERARCHY)-1), \n",
    "        [\"error_rate\", \"hier_dist_mistake\", \"hier_dist\"],\n",
    "    ],\n",
    "    names=['level', 'metric'],\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(index=index, columns=columns, dtype=float)\n",
    "\n",
    "# Uncomment to compute metrics\n",
    "# for lvl, metric in tqdm(df, total=len(columns)):\n",
    "#     func = partial(globals()[metric], k=1, level=lvl)\n",
    "#     df[(lvl, metric)] = df.index.map(func)\n",
    "# df.to_pickle(PATH_RESULTS / f\"{DATASET}.pkl\")\n",
    "\n",
    "df = pd.read_pickle(PATH_RESULTS / f\"{DATASET}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5bd67-d97c-4fb7-83eb-5dec8b69267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba848c-ded6-4ead-8100-53ae8b94d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(exp: str):\n",
    "    print(exp)\n",
    "    return df.loc[experiments[exp], :].mean(), df.loc[experiments[exp], :].std()\n",
    "\n",
    "def std(exp: str, level: int = 0, k: int = 1):\n",
    "    return utils.hier_dist_mistake(*preds_labels(exp), HIERARCHY, level, k)\n",
    "\n",
    "\n",
    "index =  pd.Index(\n",
    "    data=experiments.keys(), \n",
    "    dtype=str, \n",
    "    name=\"experiments\",\n",
    ")\n",
    "\n",
    "columns = pd.MultiIndex.from_product(\n",
    "    iterables=[\n",
    "        range(len(HIERARCHY)-1), \n",
    "        [\"error_rate\", \"hier_dist_mistake\", \"hier_dist\"],\n",
    "        [\"mean\", \"std\"],\n",
    "    ],\n",
    "    names=['level', 'metric', None],\n",
    ")\n",
    "\n",
    "DF = pd.DataFrame(index=index, columns=columns, dtype=float)\n",
    "\n",
    "for idx, row in DF.iterrows():\n",
    "    row.loc[pd.IndexSlice[:, :, \"mean\"]] = df.loc[experiments[idx], :].mean()\n",
    "    row.loc[pd.IndexSlice[:, :, \"std\"]] = df.loc[experiments[idx], :].std()\n",
    "\n",
    "DF.loc[:, pd.IndexSlice[:, :, \"mean\"]].style.background_gradient(axis=0, cmap=\"Greens_r\")\n",
    "#DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791be9d6-c945-4465-88a6-cf85db3940fd",
   "metadata": {},
   "source": [
    "# Quantity vs Quality: various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f401f-28b8-4e91-bc42-173ef2a13349",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = {\n",
    "    \"xe-onehot\": \"One-hot + Cross Entropy\",\n",
    "    \"xe-b3p-beta0.3\": \"Hier. b3p + Cross Entropy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839efcb-9f85-42e6-b45b-b16ab65da2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set those according to number of level in hierarchy\n",
    "NROWS = 2\n",
    "NCOLS = 3\n",
    "\n",
    "plt.style.use('default')\n",
    "figsize = (3 * NCOLS, 3 * NROWS)\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=NROWS,\n",
    "    ncols=NCOLS,\n",
    "    figsize=figsize,\n",
    ")\n",
    "\n",
    "for lvl, ax in enumerate(axs.ravel()):\n",
    "    for exp, label in EXPERIMENTS.items():\n",
    "        ax.errorbar(\n",
    "            DF.loc[exp, (lvl, \"error_rate\", \"mean\")],\n",
    "            DF.loc[exp, (lvl, \"hier_dist_mistake\", \"mean\")],\n",
    "            #xerr=DF.loc[exp, (lvl, \"error_rate\", \"std\")],\n",
    "            #yerr=DF.loc[exp, (lvl, \"hier_dist_mistake\", \"std\")],\n",
    "            fmt='o',\n",
    "            label=label,\n",
    "        )\n",
    "    ax.set_title(f\"Level {lvl}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(\n",
    "    loc='lower center',\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    bbox_to_anchor=(0.5, -0.2),\n",
    "    ncol=NCOLS,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a1fa5-d0c9-43da-a7a3-8cf6b0a1400b",
   "metadata": {},
   "source": [
    "# Quantity vs Quality: Perotti et. al (b3p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e5d1d-7052-46f4-830f-b499dd6ac29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = df[df.index.str.contains('xe-b3p')]\n",
    "HYPERPARAM = np.arange(0.1, 1, 0.1)\n",
    "\n",
    "cmap = plt.get_cmap('viridis')\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    EXPERIMENTS[0]['error_rate'],\n",
    "    EXPERIMENTS[0]['hier_dist_mistake'],\n",
    "    c=HYPERPARAM,\n",
    "    cmap=cmap,\n",
    "    marker='o',\n",
    ")\n",
    "\n",
    "# Add a colorbar to the plot\n",
    "cbar = plt.colorbar(scatter, ax=ax, label=r'$\\alpha$')\n",
    "\n",
    "# Add labels and a title\n",
    "ax.set_xlabel('Error Rate')\n",
    "ax.set_ylabel('Hier Dist Mistake')\n",
    "ax.set_title('b3p: hyper-param tradeoff')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb70a9e-f559-45a2-9532-74ee308e0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"figures/slides/metropolis.mplstyle\")\n",
    "\n",
    "lvl = 0\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "# Scatter plots\n",
    "scatter1 = ax.errorbar(\n",
    "    df.loc[experiments[\"xe-onehot\"], pd.IndexSlice[lvl, [\"error_rate\"]]].mean(),\n",
    "    df.loc[experiments[\"xe-onehot\"], pd.IndexSlice[lvl, [\"hier_dist_mistake\"]]].mean(),\n",
    "    xerr=df.loc[experiments[\"xe-onehot\"], pd.IndexSlice[lvl, [\"error_rate\"]]].std(), \n",
    "    yerr=df.loc[experiments[\"xe-onehot\"], pd.IndexSlice[lvl, [\"hier_dist_mistake\"]]].std(),\n",
    "    fmt='o',\n",
    "    label='One-hot enc.\\nCross Entropy',\n",
    ")\n",
    "scatter2 = ax.errorbar(\n",
    "    df.loc[experiments[\"xe-b3p-beta0.4\"], pd.IndexSlice[lvl, [\"error_rate\"]]].mean(),\n",
    "    df.loc[experiments[\"xe-b3p-beta0.4\"], pd.IndexSlice[lvl, [\"hier_dist_mistake\"]]].mean(),\n",
    "    xerr=df.loc[experiments[\"xe-b3p-beta0.4\"], pd.IndexSlice[lvl, [\"error_rate\"]]].std(), \n",
    "    yerr=df.loc[experiments[\"xe-b3p-beta0.4\"], pd.IndexSlice[lvl, [\"hier_dist_mistake\"]]].std(),\n",
    "    fmt='o',\n",
    "    label='Hierarchical enc.\\nCross Entropy',\n",
    ")\n",
    "scatter3 = ax.errorbar(\n",
    "    df.loc[experiments[\"cd-desc-pca-n_components100\"], pd.IndexSlice[lvl, [\"error_rate\"]]].mean(),\n",
    "    df.loc[experiments[\"cd-desc-pca-n_components100\"], pd.IndexSlice[lvl, [\"hier_dist_mistake\"]]].mean(),\n",
    "    xerr=df.loc[experiments[\"cd-desc-pca-n_components100\"], pd.IndexSlice[lvl, [\"error_rate\"]]].std(), \n",
    "    yerr=df.loc[experiments[\"cd-desc-pca-n_components100\"], pd.IndexSlice[lvl, [\"hier_dist_mistake\"]]].std(),\n",
    "    fmt='o',\n",
    "    label='Description enc.\\nCosine Distance',\n",
    ")\n",
    "\n",
    "\n",
    "# Get the legend handles and labels\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# Customize the legend markers\n",
    "new_handles = [\n",
    "    plt.Line2D([], [], marker='o', markersize=7, linestyle='', color=scatter1.lines[0].get_color()),\n",
    "    plt.Line2D([], [], marker='o', markersize=7, linestyle='', color=scatter2.lines[0].get_color()),\n",
    "    plt.Line2D([], [], marker='o', markersize=7, linestyle='', color=scatter3.lines[0].get_color()),\n",
    "]\n",
    "ax.legend(\n",
    "    loc='center left',\n",
    "    handles=new_handles,\n",
    "    labels=labels,\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    "    labelspacing=1.5,\n",
    "    fontsize=8,\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_xlim(0.268, 0.2858) \n",
    "ax.set_xticks([0.270, 0.273, 0.276, 0.279, 0.282, 0.286])\n",
    "ax.set_xticklabels(\n",
    "    [\"27.0\", \"27.3\", \"27.6\", \"27.9\", \"28.2\", \"Error \\%\"],\n",
    "    va='top',\n",
    ")\n",
    "\n",
    "ax.set_ylim(2.24, 2.50) \n",
    "ax.set_yticks([2.26, 2.30, 2.34, 2.38, 2.42, 2.46, 2.50])\n",
    "ax.set_yticklabels([\"2.26\", \"2.30\", \"2.34\", \"2.38\", \"2.42\", \"2.46\", \"Hierarchical\\ndist. mistake\"])\n",
    "\n",
    "\n",
    "plt.subplots_adjust(right=0.68) \n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"figures/slides/CIFAR100/scatter.pgf\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455000be-9267-4e8e-820c-e344853b8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_descriptions_encodings(level: int):\n",
    "\n",
    "    assert 1 < level < 5\n",
    "    \n",
    "    COLOR_MAP = {\n",
    "        2: [\n",
    "            \"#332288\", \"#6699cc\", \"#88ccee\", \"#117733\", \n",
    "            \"#999933\", \"#ddcc77\", \"#cc6677\", \"#882255\",\n",
    "        ],\n",
    "        3: [\n",
    "            \"#332288\", \"#6699cc\", \"#ddcc77\", \"#cc6677\",\n",
    "        ],\n",
    "        4: [\n",
    "            \"#6699cc\", \"#cc6677\",\n",
    "        ]\n",
    "    }\n",
    "        \n",
    "    CLASSES = {\n",
    "        2 : [\n",
    "            \"Flora\", \"Fishes \\& Aq. Mammals\", \"Terrestrial Mammals\",\n",
    "            \"Household Items\", \"Non-Mammals\", \"Vehicles\", \n",
    "            \"Buildings\", \"Natural Landscapes\",\n",
    "        ],\n",
    "        3 : [\n",
    "            \"Flora\", \"Fauna\", \"Man-Made Objects\", \"Natural Landscapes\",\n",
    "        ],\n",
    "        4 : [\n",
    "            \"Living Beings\", \"Non-Living Subjects\",\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    labels = HIERARCHY[level]\n",
    "    color = [COLOR_MAP[level][label] for label in labels]\n",
    "    \n",
    "    x, y = np.load(\"n_components2.npy\").T\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    scatter = ax.scatter(x, y, c=color, s=20)\n",
    "    \n",
    "    handles = [\n",
    "        plt.Line2D([], [], marker='o', markersize=7, linestyle='', color=color, label=label)\n",
    "        for color, label in zip(COLOR_MAP[level], CLASSES[level])\n",
    "    ]\n",
    "    ax.legend(\n",
    "        loc='center left',\n",
    "        handles=handles,\n",
    "        bbox_to_anchor=(1, 0.5),\n",
    "        labelspacing=1.5,\n",
    "        fontsize=8,\n",
    "    )\n",
    "    \n",
    "    # Remove ticks and tick labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    fig.tight_layout()\n",
    "\n",
    "    \n",
    "    plt.subplots_adjust(right=0.57) \n",
    "\n",
    "\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.savefig(f\"figures/slides/CIFAR100/encodings-level{level}.pgf\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_2d_descriptions_encodings(level=2)\n",
    "plot_2d_descriptions_encodings(level=3)\n",
    "plot_2d_descriptions_encodings(level=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97940576-e687-45b5-9945-f68bde06a2b9",
   "metadata": {},
   "source": [
    "# Quantity vs Quality: Bertinetto et. al (mbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d57ae-b0c4-41fa-aa2f-25767a7b813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = df[df.index.str.contains('xe-mbm')]\n",
    "HYPERPARAM = [1, 2, 3, 4, 5, 10, 15, 20, 30]\n",
    "\n",
    "cmap = plt.get_cmap('viridis')\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    EXPERIMENTS[0]['error_rate'],\n",
    "    EXPERIMENTS[0]['hier_dist_mistake'],\n",
    "    c=HYPERPARAM,\n",
    "    cmap=cmap,\n",
    "    marker='o',\n",
    ")\n",
    "\n",
    "# Add a colorbar to the plot\n",
    "cbar = plt.colorbar(scatter, ax=ax, label=r'$\\alpha$')\n",
    "\n",
    "# Add labels and a title\n",
    "ax.set_xlabel('Error Rate')\n",
    "ax.set_ylabel('Hier Dist Mistake')\n",
    "ax.set_title('mbm: hyper-param tradeoff')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
